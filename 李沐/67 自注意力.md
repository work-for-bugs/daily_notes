[本节教材链接](https://zh.d2l.ai/chapter_attention-mechanisms/self-attention-and-positional-encoding.html#fig-cnn-rnn-self-attention)
# 自注意力
![alt text](image-28.png)
# 跟CNN，RNN对比
![alt text](image-29.png)
# 位置编码
![alt text](image-30.png)
位置信息直接加进去，没有concat   
# 位置编码矩阵
![alt text](image-31.png)
# 绝对位置信息
![alt text](image-32.png)
# 相对位置信息
![alt text](image-33.png)
# 总结
![alt text](image-34.png)

# 代码

# 答疑
